rosinit('192.168.27.1'); % If unsure, please ask a tutor
jointStateSubscriber = rossubscriber('/ur/joint_states','sensor_msgs/JointState');
%%
jointStateSubscriber = rossubscriber('/ur/joint_states','sensor_msgs/JointState');
pause(2); % Pause to give time for a message to appear
currentJointState_321456 = (jointStateSubscriber.LatestMessage.Position)'; % Note the default order of the joints is 3,2,1,4,5,6
currentJointState_123456 = [currentJointState_321456(3:-1:1),currentJointState_321456(4:6)];
jointStateSubscriber.LatestMessage
jointNames = {'shoulder_pan_joint','shoulder_lift_joint', 'elbow_joint', 'wrist_1_joint', 'wrist_2_joint', 'wrist_3_joint'};
[client, goal] = rosactionclient('/ur/scaled_pos_joint_traj_controller/follow_joint_trajectory');
goal.Trajectory.JointNames = jointNames;
goal.Trajectory.Header.Seq = 1;
goal.Trajectory.Header.Stamp = rostime('Now','system');
goal.GoalTimeTolerance = rosduration(0.05);
bufferSeconds = 1; % This allows for the time taken to send the message. If the network is fast, this could be reduced.
durationSeconds = 5; % This is how many seconds the movement will take

startJointSend = rosmessage('trajectory_msgs/JointTrajectoryPoint');
startJointSend.Positions = currentJointState_123456;
startJointSend.TimeFromStart = rosduration(0);     
      
endJointSend = rosmessage('trajectory_msgs/JointTrajectoryPoint');
nextJointState_123456 = currentJointState_123456 + [pi/8,0,0,0,0,pi/8];
endJointSend.Positions = nextJointState_123456;
endJointSend.TimeFromStart = rosduration(durationSeconds);

goal.Trajectory.Points = [startJointSend; endJointSend];
goal.Trajectory.Header.Stamp = jointStateSubscriber.LatestMessage.Header.Stamp + rosduration(bufferSeconds);
sendGoal(client,goal);
%%
openService = rossvcclient("/onrobot/open", "std_srvs/Trigger");
closeService = rossvcclient("/onrobot/close", "std_srvs/Trigger");
openService.call();
closeService.call();
%%
%%CHATGPT INPUT

import cv2

# Capture image from camera (assuming you have a ROS topic publishing RGB-D data)
image = cv2.imread("camera_image.jpg") # Replace with ROS topic subscription

# Detect pattern (example: detect a circle in the image)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=100)

# Use detected pattern to compute motion
if circles is not None:
    for circle in circles[0, :]:
        center_x, center_y, radius = circle

        # Compute motion (pseudo code)
        # Depending on the pattern's location, calculate the desired joint angles
        next_joint_state = ... # Update nextJointState_123456 based on pattern position
nextJointState_123456 = currentJointState_123456 + [delta_pan, delta_lift, delta_elbow, 0, 0, delta_wrist3];
endJointSend.Positions = nextJointState_123456;
imageSub = rossubscriber('/camera/rgb/image_raw');
img = readImage(imageSub.LatestMessage);
imshow(img);
// Pseudo-code for visual servoing loop
visp::vpServo task;
// Define desired visual features and update robot control
task.addFeature(...);
task.computeControlLaw();
